# -*- coding: utf-8 -*-
"""
è”é‚¦å­¦ä¹ è®­ç»ƒä¸»è„šæœ¬
"""

import os
import sys
import torch
import random
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from models.TimeLLM import Model
from dataset.data_loader import get_federated_data
from utils.config import get_args
from federated.client import FederatedClient
from federated.server import FederatedServer
from torch.utils.data import DataLoader
from utils.utils import assign_model_to_client, cleanup_client_model

# è®¾ç½®ç¦»çº¿æ¨¡å¼ï¼Œé˜²æ­¢è‡ªåŠ¨è”ç½‘
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1"


class ModelConfig:
    """TimeLLMæ¨¡å‹é…ç½®ç±» - ä¿®å¤ç‰ˆæœ¬"""

    def __init__(self, args):
        self.task_name = 'long_term_forecast'
        self.seq_len = args.seq_len
        self.pred_len = args.pred_len
        self.enc_in = 1
        self.d_model = args.d_model
        self.n_heads = args.n_heads
        self.d_ff = args.d_model * 4

        # LLMé…ç½® - æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®
        self.llm_model = getattr(args, 'llm_model_name', 'Qwen3')

        # åˆå§‹è®¾ç½®ï¼Œä¼šåœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶æ›´æ–°ä¸ºå®é™…å€¼
        if self.llm_model == 'Qwen3':
            self.llm_dim = 1024  # Qwen3-0.6Bçš„éšè—ç»´åº¦ï¼ˆåˆå§‹å€¼ï¼‰
            self.llm_layers = min(6, getattr(args, 'llm_layers', 6))
        elif self.llm_model == 'GPT2':
            self.llm_dim = 768
            self.llm_layers = 6
        else:
            self.llm_dim = 768  # é»˜è®¤å€¼
            self.llm_layers = 6

        # è¡¥ä¸é…ç½®
        self.patch_len = 16
        self.stride = 8

        self.dropout = args.dropout
        self.prompt_domain = True
        self.content = "The dataset records the wireless traffic of a certain base station"

        # LoRAé…ç½®
        self.use_lora = getattr(args, 'use_lora', False)
        if self.use_lora:
            self.lora_rank = getattr(args, 'lora_rank', 8)
            self.lora_alpha = getattr(args, 'lora_alpha', 16)
            self.lora_dropout = getattr(args, 'lora_dropout', 0.1)
            self.lora_target_modules = getattr(args, 'lora_target_modules',
                                               ["q_proj", "k_proj", "v_proj", "o_proj"])


def set_seed(seed):
    """è®¾ç½®éšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)


def create_client_data_loaders(federated_data, args):
    """ä¸ºæ‰€æœ‰å®¢æˆ·ç«¯åˆ›å»ºæ•°æ®åŠ è½½å™¨ - åŒ…å«è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•é›†"""
    client_loaders = {}

    for client_id, client_data in federated_data['clients'].items():
        sequences = client_data['sequences']
        client_loaders[client_id] = {}

        # è®­ç»ƒé›†
        if 'train' in sequences:
            X_train = torch.FloatTensor(sequences['train']['history'])
            y_train = torch.FloatTensor(sequences['train']['target'])
            train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
            client_loaders[client_id]['train'] = DataLoader(
                train_dataset, batch_size=args.local_bs, shuffle=True
            )
            client_loaders[client_id]['num_samples'] = len(train_dataset)

        # éªŒè¯é›†
        if 'val' in sequences:
            X_val = torch.FloatTensor(sequences['val']['history'])
            y_val = torch.FloatTensor(sequences['val']['target'])
            val_dataset = torch.utils.data.TensorDataset(X_val, y_val)
            client_loaders[client_id]['val'] = DataLoader(
                val_dataset, batch_size=args.local_bs, shuffle=False
            )

        # æµ‹è¯•é›†
        if 'test' in sequences:
            X_test = torch.FloatTensor(sequences['test']['history'])
            y_test = torch.FloatTensor(sequences['test']['target'])
            test_dataset = torch.utils.data.TensorDataset(X_test, y_test)
            client_loaders[client_id]['test'] = DataLoader(
                test_dataset, batch_size=args.local_bs, shuffle=False
            )

    return client_loaders


def create_federated_clients(federated_data, client_loaders, args):
    """åˆ›å»ºè”é‚¦å®¢æˆ·ç«¯ - æ”¯æŒå¤šç§æ•°æ®åŠ è½½å™¨å’ŒçœŸå®æ•°æ®"""
    clients = []

    for client_id in federated_data['clients'].keys():
        # è·å–è¯¥å®¢æˆ·ç«¯çš„çœŸå®åæ ‡å’Œæµé‡ç»Ÿè®¡ä¿¡æ¯
        client_data = federated_data['clients'][client_id]
        coordinates = client_data['coordinates']
        original_traffic_stats = client_data['original_traffic_stats']

        # åˆ›å»ºå®¢æˆ·ç«¯ï¼Œä¼ é€’çœŸå®çš„åæ ‡å’Œæµé‡æ•°æ®
        client = FederatedClient(
            client_id=client_id,
            model=None,  # æš‚æ—¶ä¸åˆ†é…æ¨¡å‹
            data_loader=client_loaders[client_id]['train'],  # ä¸»è¦è®­ç»ƒæ•°æ®
            args=args,
            coordinates=coordinates,  # çœŸå®åæ ‡
            original_traffic_stats=original_traffic_stats  # çœŸå®æµé‡ç»Ÿè®¡
        )

        # æ·»åŠ éªŒè¯å’Œæµ‹è¯•æ•°æ®åŠ è½½å™¨
        if 'val' in client_loaders[client_id]:
            client.val_loader = client_loaders[client_id]['val']
        if 'test' in client_loaders[client_id]:
            client.test_loader = client_loaders[client_id]['test']

        clients.append(client)

    return clients

def generate_method_name(args):
    """ç”Ÿæˆæ¸…æ™°çš„æ–¹æ³•åç§°"""
    aggregation_map = {
        'lora_fedavg': 'FedAvg',
        'lora_fedprox': 'FedProx',
        'fedatt': 'FedAtt',
        'fedda': 'FedDA',
        'enhanced_multi_dim_llm': 'FSTLM'
    }

    base_name = aggregation_map.get(args.aggregation, args.aggregation)

    suffixes = []
    if args.use_lora:
        suffixes.append('LoRA')
    if args.enable_augmentation:
        suffixes.append('Aug')

    if suffixes:
        return f"{base_name}+{'+'.join(suffixes)}"
    else:
        return base_name


def generate_dataset_name(args):
    """ç”Ÿæˆå®Œæ•´çš„æ•°æ®é›†åç§°"""
    base_name = os.path.splitext(args.file_path)[0]
    return f"{base_name}_{args.data_type}"

def main():
    """ä¸»å‡½æ•°"""
    # è·å–å‚æ•°
    args = get_args()

    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)

    print("=== è”é‚¦å­¦ä¹ è®­ç»ƒ ===")
    print(f"è®¾å¤‡: {args.device}")
    print(f"æ•°æ®é›†: {args.file_path} ({args.data_type})")
    print(f"å®¢æˆ·ç«¯æ•°é‡: {args.num_clients}")
    print(f"å‚ä¸æ¯”ä¾‹: {args.frac}")
    print(f"æ€»è½®æ•°: {args.rounds}")
    print(f"æœ¬åœ°è®­ç»ƒè½®æ•°: {args.local_epochs}")
    print(f"èšåˆç®—æ³•: {args.aggregation}")

    # åˆå§‹åŒ–ç»“æœä¿å­˜å™¨ - ä½¿ç”¨æ–°çš„å‘½åå‡½æ•°
    from utils.results_saver import ResultsSaver
    dataset_name = generate_dataset_name(args)
    method_name = generate_method_name(args)

    results_saver = ResultsSaver(args.save_dir, dataset_name)
    print(f"æ•°æ®é›†: {dataset_name}")
    print(f"æ–¹æ³•: {method_name}")
    print(f"ç»“æœå°†ä¿å­˜è‡³: {results_saver.csv_file}")

    # åŠ è½½è”é‚¦æ•°æ®
    print("\nåŠ è½½è”é‚¦æ•°æ®...")
    federated_data, _ = get_federated_data(args)

    # éªŒè¯å’Œå±•ç¤ºçœŸå®æ•°æ®ï¼ˆæ–°å¢ï¼‰
    from utils.utils import validate_real_data, print_real_data_summary

    if validate_real_data(federated_data):
        print_real_data_summary(federated_data)
    else:
        print("æ•°æ®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
        return

    # åˆ›å»ºå®¢æˆ·ç«¯æ•°æ®åŠ è½½å™¨
    print("\nåˆ›å»ºå®¢æˆ·ç«¯æ•°æ®åŠ è½½å™¨...")
    client_loaders = create_client_data_loaders(federated_data, args)

    # åˆå§‹åŒ–å…¨å±€æ¨¡å‹
    print("åˆå§‹åŒ–å…¨å±€æ¨¡å‹...")
    global_model = Model(ModelConfig(args)).to(args.device)

    # åˆ›å»ºè”é‚¦å®¢æˆ·ç«¯ï¼ˆç°åœ¨ä¼šä¼ é€’çœŸå®æ•°æ®ï¼‰
    print("åˆ›å»ºè”é‚¦å®¢æˆ·ç«¯...")
    clients = create_federated_clients(federated_data, client_loaders, args)
    print(f"æˆåŠŸåˆ›å»º {len(clients)} ä¸ªå®¢æˆ·ç«¯")

    # æ‰“å°å®¢æˆ·ç«¯çœŸå®æ•°æ®æ ·æœ¬ï¼ˆæ–°å¢ï¼‰
    print("\nå®¢æˆ·ç«¯çœŸå®æ•°æ®æ ·æœ¬:")
    sample_client = clients[0]
    print(f"  åŸºç«™ {sample_client.client_id}:")
    print(f"    åæ ‡: ({sample_client.coordinates['lng']:.3f}, {sample_client.coordinates['lat']:.3f})")
    traffic_stats = sample_client.get_real_traffic_stats()
    print(f"    æµé‡ç»Ÿè®¡: å‡å€¼={traffic_stats['mean']:.1f}, è¶‹åŠ¿={traffic_stats['trend']}")
    print(f"    å˜å¼‚ç³»æ•°: {traffic_stats.get('coefficient_of_variation', 0):.3f}")

    # åˆ›å»ºè”é‚¦æœåŠ¡å™¨
    server = FederatedServer(global_model, args)

    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¢å¤è®­ç»ƒ
    start_round = 1
    best_val_loss = float('inf')

    if args.resume:
        try:
            start_round, best_val_loss = server.load_checkpoint(args.resume)
            print(f"ä»è½®æ¬¡ {start_round} æ¢å¤è®­ç»ƒï¼Œå½“å‰æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
        except Exception as e:
            print(f"æ¢å¤æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            print("å°†ä»å¤´å¼€å§‹è®­ç»ƒ")
            start_round = 1
            best_val_loss = float('inf')

    # å¼€å§‹è”é‚¦è®­ç»ƒ
    print(f"\nå¼€å§‹è”é‚¦è®­ç»ƒ (ä»è½®æ¬¡ {start_round} åˆ° {args.rounds})...")

    for round_idx in range(start_round, args.rounds + 1):
        print(f"\n{'=' * 50}")
        print(f"è”é‚¦å­¦ä¹ è½®æ¬¡: {round_idx}/{args.rounds}")

        # æ˜¾ç¤ºå½“å‰æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
        if torch.cuda.is_available():
            memory_allocated = torch.cuda.memory_allocated() / 1024 ** 3  # GB
            memory_reserved = torch.cuda.memory_reserved() / 1024 ** 3  # GB
            print(f"GPUæ˜¾å­˜ä½¿ç”¨: {memory_allocated:.2f}GB / {memory_reserved:.2f}GB")

        # æ‰§è¡Œä¸€è½®è”é‚¦å­¦ä¹ 
        round_results = server.federated_round(clients, round_idx)

        # è·å–æœ¬è½®é€‰ä¸­çš„å®¢æˆ·ç«¯
        selected_clients = round_results.get('selected_client_objects', [])

        # è¾“å‡ºæœ¬è½®ç»“æœï¼ˆå¢å¼ºç‰ˆï¼‰
        avg_loss = round_results['avg_client_loss']
        print(f"æœ¬è½®å¹³å‡å®¢æˆ·ç«¯æŸå¤±: {avg_loss:.6f}")

        # å¦‚æœæœ‰éªŒè¯æŸå¤±ï¼Œä¹Ÿè¾“å‡º
        if 'val_loss' in round_results:
            print(f"æœ¬è½®éªŒè¯é›†æŸå¤±: {round_results['val_loss']:.6f}")

        # æ¯éš”ä¸€å®šè½®æ•°è¿›è¡Œå…¨å±€è¯„ä¼°
        if round_idx % args.eval_every == 0:
            print("è¿›è¡Œå…¨å±€æ¨¡å‹è¯„ä¼°...")

            eval_clients = selected_clients[:min(10, len(selected_clients))] if selected_clients else clients[:min(10, len(clients))]

            # éªŒè¯é›†è¯„ä¼°ï¼ˆå¸¦MSEå’ŒMAEï¼‰
            val_metrics = None
            if hasattr(eval_clients[0], 'val_loader'):
                val_metrics, val_client_metrics = server.evaluate_global_model_with_metrics(eval_clients, 'val')
                server.train_history['global_loss'].append(val_metrics['mse'])  # ä¿æŒå…¼å®¹æ€§
                print(f"å…¨å±€éªŒè¯æ€§èƒ½: MSE={val_metrics['mse']:.6f}, MAE={val_metrics['mae']:.6f}")

                # ä¿å­˜æœ€ä¼˜æ¨¡å‹
                if args.save_best_model and val_metrics['mse'] < best_val_loss:
                    best_val_loss = val_metrics['mse']
                    best_model_path = f"{args.save_dir}/best_model.pth"
                    server.save_best_model(best_model_path, val_metrics['mse'], round_idx)
                    print(f"ğŸ¯ å‘ç°æ›´ä¼˜æ¨¡å‹ï¼éªŒè¯MSE: {val_metrics['mse']:.6f}")

            # æµ‹è¯•é›†è¯„ä¼°ï¼ˆæ¯è½®éƒ½åšï¼Œç”¨äºä¿å­˜ç»“æœï¼‰
            test_metrics = None
            if hasattr(eval_clients[0], 'test_loader'):
                test_metrics, test_client_metrics = server.evaluate_global_model_with_metrics(eval_clients, 'test')
                print(f"æµ‹è¯•é›†æ€§èƒ½: MSE={test_metrics['mse']:.6f}, MAE={test_metrics['mae']:.6f}")

            # ä¿å­˜æœ¬è½®ç»“æœ
            results_saver.save_round_results(
                round_idx=round_idx,
                test_metrics=test_metrics,
                val_metrics=val_metrics,
                train_loss=avg_loss,
                method_name=method_name,
                num_clients=len(selected_clients) if selected_clients else args.num_clients,
                aggregation=args.aggregation
            )

        # ä¿å­˜æ£€æŸ¥ç‚¹
        if args.save_checkpoint and round_idx % args.checkpoint_interval == 0:
            checkpoint_path = f"{args.save_dir}/checkpoint_round_{round_idx}.pth"
            server.save_checkpoint(checkpoint_path, round_idx, best_val_loss)

    # è®­ç»ƒç»“æŸï¼Œä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹
    if args.save_checkpoint:
        final_checkpoint_path = f"{args.save_dir}/final_checkpoint.pth"
        server.save_checkpoint(final_checkpoint_path, args.rounds, best_val_loss)
        print(f"æœ€ç»ˆæ£€æŸ¥ç‚¹å·²ä¿å­˜: {final_checkpoint_path}")

    print("\nè”é‚¦è®­ç»ƒå®Œæˆ!")

    # æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°
    print("\n=== æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼° ===")
    final_test_metrics, final_test_client_metrics = server.evaluate_global_model_with_metrics(clients, 'test')
    print(f"æœ€ç»ˆæµ‹è¯•æ€§èƒ½: MSE={final_test_metrics['mse']:.6f}, MAE={final_test_metrics['mae']:.6f}")

    # ä¿å­˜æœ€ç»ˆç»“æœ
    additional_info = {
        'final_test_metrics': final_test_metrics,
        'final_test_client_metrics': final_test_client_metrics,
        'best_val_loss': best_val_loss,
        'args': vars(args)
    }

    final_results = results_saver.save_final_results(additional_info)

    # è¾“å‡ºè®­ç»ƒæ‘˜è¦
    train_history = server.get_train_history()

    print(f"\n{'=' * 60}")
    print("è®­ç»ƒæ‘˜è¦")
    print(f"{'=' * 60}")

    # è®­ç»ƒæŸå¤±
    final_client_loss = train_history['client_losses'][-1] if train_history['client_losses'] else float('inf')
    print(f"æœ€ç»ˆå¹³å‡å®¢æˆ·ç«¯è®­ç»ƒæŸå¤±: {final_client_loss:.6f}")

    # æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡
    print(f"æœ€ç»ˆæµ‹è¯•MSE: {final_test_metrics['mse']:.6f}")
    print(f"æœ€ç»ˆæµ‹è¯•MAE: {final_test_metrics['mae']:.6f}")

    # æœ€ä½³æ€§èƒ½
    summary = final_results['summary']
    if 'best_test_mse' in summary:
        print(f"æœ€ä½³æµ‹è¯•MSE: {summary['best_test_mse']:.6f}")
        print(f"æœ€ä½³æµ‹è¯•MAE: {summary['best_test_mae']:.6f}")

    # æ¨¡å‹ä¿å­˜æ‘˜è¦
    if args.save_best_model:
        print(f"\nğŸ“ æ¨¡å‹ä¿å­˜ä¿¡æ¯:")
        print(f"   æœ€ä¼˜æ¨¡å‹: {args.save_dir}/best_model.pth")
        print(f"   æœ€ä¼˜éªŒè¯MSE: {best_val_loss:.6f}")

    if args.save_checkpoint:
        print(f"   æœ€ç»ˆæ£€æŸ¥ç‚¹: {args.save_dir}/final_checkpoint.pth")
        print(f"   æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”: æ¯ {args.checkpoint_interval} è½®")

    # å¦‚æœä½¿ç”¨å¤šç»´åº¦LLMèšåˆï¼Œç”Ÿæˆè¶‹åŠ¿åˆ†æ
    if args.aggregation in ['multi_dim_llm', 'enhanced_multi_dim_llm']:
        print(f"\n{'=' * 60}")
        print("å®¢æˆ·ç«¯å­¦ä¹ è¶‹åŠ¿åˆ†æ")
        print(f"{'=' * 60}")

        try:
            from utils.trend_visualizer import visualize_trends
            visualize_trends(server, args.save_dir)
        except Exception as e:
            print(f"è¶‹åŠ¿åˆ†æç”Ÿæˆå¤±è´¥: {e}")
            # è‡³å°‘æ‰“å°åŸºæœ¬çš„è¶‹åŠ¿æ‘˜è¦
            if hasattr(server, 'client_history') and server.client_history['losses']:
                print(f"å‚ä¸è®­ç»ƒçš„å®¢æˆ·ç«¯æ•°é‡: {len(server.client_history['losses'])}")

                # æ˜¾ç¤ºå„å®¢æˆ·ç«¯çš„åŸºæœ¬è¶‹åŠ¿ä¿¡æ¯
                for client_id in server.client_history['losses'].keys():
                    trend_summary = server.get_client_trend_summary(client_id)
                    print(f"  å®¢æˆ·ç«¯ {client_id}: {trend_summary['description']} (è¯„åˆ†: {trend_summary['score']:.2f})")

    # ä¿å­˜è¯¦ç»†ç»“æœ
    print(f"\n=== ç»“æœå·²ä¿å­˜ ===")
    print(f"CSVç»“æœ: {results_saver.csv_file}")
    print(f"è¯¦ç»†ç»“æœ: {results_saver.json_file}")
    print("å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤åˆ†æç»“æœ:")
    print(f"python analyze_results.py --dataset {dataset_name}")


if __name__ == "__main__":
    main()