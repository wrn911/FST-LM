# -*- coding: utf-8 -*-
"""
è”é‚¦å­¦ä¹ èšåˆç®—æ³• - æ·»åŠ LoRAæ”¯æŒ
"""
import numpy as np
import torch
import copy
from typing import List, Dict

from scipy import linalg


class FedAvgAggregator:
    """FedAvgèšåˆç®—æ³•"""

    def __init__(self):
        pass

    def aggregate(self, client_models: List[Dict], client_weights: List[float] = None):
        """
        èšåˆå®¢æˆ·ç«¯æ¨¡å‹å‚æ•°

        Args:
            client_models: å®¢æˆ·ç«¯æ¨¡å‹å‚æ•°åˆ—è¡¨
            client_weights: å®¢æˆ·ç«¯æƒé‡åˆ—è¡¨

        Returns:
            aggregated_model: èšåˆåçš„æ¨¡å‹å‚æ•°
        """
        if not client_models:
            raise ValueError("å®¢æˆ·ç«¯æ¨¡å‹åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        # å¦‚æœæ²¡æœ‰æä¾›æƒé‡ï¼Œåˆ™ä½¿ç”¨å¹³å‡æƒé‡
        if client_weights is None:
            client_weights = [1.0 / len(client_models)] * len  # -*- coding: utf-8 -*-


"""
è”é‚¦å­¦ä¹ èšåˆç®—æ³• - æ·»åŠ LoRAæ”¯æŒ
"""

import torch
import copy
from typing import List, Dict


class FedAvgAggregator:
    """FedAvgèšåˆç®—æ³•"""

    def __init__(self):
        pass

    def aggregate(self, client_models: List[Dict], client_weights: List[float] = None):
        """
        èšåˆå®¢æˆ·ç«¯æ¨¡å‹å‚æ•°

        Args:
            client_models: å®¢æˆ·ç«¯æ¨¡å‹å‚æ•°åˆ—è¡¨
            client_weights: å®¢æˆ·ç«¯æƒé‡åˆ—è¡¨

        Returns:
            aggregated_model: èšåˆåçš„æ¨¡å‹å‚æ•°
        """
        if not client_models:
            raise ValueError("å®¢æˆ·ç«¯æ¨¡å‹åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        # å¦‚æœæ²¡æœ‰æä¾›æƒé‡ï¼Œåˆ™ä½¿ç”¨å¹³å‡æƒé‡
        if client_weights is None:
            client_weights = [1.0 / len(client_models)] * len(client_models)

        # ç¡®ä¿æƒé‡æ€»å’Œä¸º1
        total_weight = sum(client_weights)
        client_weights = [w / total_weight for w in client_weights]

        # åˆå§‹åŒ–èšåˆæ¨¡å‹å‚æ•°
        aggregated_model = copy.deepcopy(client_models[0])

        # å°†ç¬¬ä¸€ä¸ªæ¨¡å‹å‚æ•°ä¹˜ä»¥å¯¹åº”æƒé‡
        for key in aggregated_model.keys():
            aggregated_model[key] = aggregated_model[key] * client_weights[0]

        # ç´¯åŠ å…¶ä»–å®¢æˆ·ç«¯çš„åŠ æƒå‚æ•°
        for i in range(1, len(client_models)):
            weight = client_weights[i]
            for key in aggregated_model.keys():
                aggregated_model[key] += client_models[i][key] * weight

        return aggregated_model


class WeightedFedAvgAggregator:
    """åŸºäºæ ·æœ¬æ•°é‡çš„åŠ æƒFedAvgèšåˆç®—æ³•"""

    def __init__(self):
        pass

    def aggregate(self, client_models: List[Dict], client_info: List[Dict]):
        """
        åŸºäºæ ·æœ¬æ•°é‡è¿›è¡ŒåŠ æƒèšåˆ

        Args:
            client_models: å®¢æˆ·ç«¯æ¨¡å‹å‚æ•°åˆ—è¡¨
            client_info: å®¢æˆ·ç«¯ä¿¡æ¯åˆ—è¡¨ï¼ˆåŒ…å«æ ·æœ¬æ•°é‡ï¼‰

        Returns:
            aggregated_model: èšåˆåçš„æ¨¡å‹å‚æ•°
        """
        if not client_models:
            raise ValueError("å®¢æˆ·ç«¯æ¨¡å‹åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        # è®¡ç®—åŸºäºæ ·æœ¬æ•°é‡çš„æƒé‡
        total_samples = sum([info['num_samples'] for info in client_info])
        client_weights = [info['num_samples'] / total_samples for info in client_info]

        # ä½¿ç”¨FedAvgè¿›è¡Œèšåˆ
        fedavg_aggregator = FedAvgAggregator()
        return fedavg_aggregator.aggregate(client_models, client_weights)


class LoRAFedAvgAggregator:
    """ä¸“é—¨ç”¨äºLoRAå‚æ•°çš„è”é‚¦èšåˆç®—æ³•"""

    def __init__(self):
        pass

    def aggregate(self, client_models: List[Dict], client_weights: List[float] = None):
        """
        åªèšåˆLoRAç›¸å…³å‚æ•°ï¼Œä¿æŒåŸºç¡€æ¨¡å‹å‚æ•°ä¸å˜

        Args:
            client_models: å®¢æˆ·ç«¯æ¨¡å‹å‚æ•°åˆ—è¡¨
            client_weights: å®¢æˆ·ç«¯æƒé‡åˆ—è¡¨

        Returns:
            aggregated_model: èšåˆåçš„æ¨¡å‹å‚æ•°
        """
        if not client_models:
            raise ValueError("å®¢æˆ·ç«¯æ¨¡å‹åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        # å¦‚æœæ²¡æœ‰æä¾›æƒé‡ï¼Œåˆ™ä½¿ç”¨å¹³å‡æƒé‡
        if client_weights is None:
            client_weights = [1.0 / len(client_models)] * len(client_models)

        # ç¡®ä¿æƒé‡æ€»å’Œä¸º1
        total_weight = sum(client_weights)
        client_weights = [w / total_weight for w in client_weights]

        # è¯†åˆ«LoRAå‚æ•°å’ŒåŸºç¡€æ¨¡å‹å‚æ•°
        lora_keys = set()
        base_keys = set()

        for key in client_models[0].keys():
            if self._is_lora_param(key):
                lora_keys.add(key)
            else:
                base_keys.add(key)

        print(f"æ£€æµ‹åˆ° {len(lora_keys)} ä¸ªLoRAå‚æ•°, {len(base_keys)} ä¸ªåŸºç¡€æ¨¡å‹å‚æ•°")

        # åˆå§‹åŒ–èšåˆæ¨¡å‹
        aggregated_model = copy.deepcopy(client_models[0])

        # åªèšåˆLoRAå‚æ•°
        for key in lora_keys:
            # é‡ç½®ä¸ºé›¶ï¼Œç„¶åç´¯åŠ åŠ æƒå‚æ•°
            aggregated_model[key] = torch.zeros_like(aggregated_model[key])
            for i, client_model in enumerate(client_models):
                aggregated_model[key] += client_model[key] * client_weights[i]

        # åŸºç¡€æ¨¡å‹å‚æ•°ä¿æŒç¬¬ä¸€ä¸ªå®¢æˆ·ç«¯çš„å€¼ï¼ˆåº”è¯¥éƒ½æ˜¯ç›¸åŒçš„å†»ç»“å‚æ•°ï¼‰
        for key in base_keys:
            aggregated_model[key] = client_models[0][key]

        return aggregated_model

    def _is_lora_param(self, param_name: str) -> bool:
        """åˆ¤æ–­å‚æ•°æ˜¯å¦ä¸ºLoRAå‚æ•°"""
        lora_keywords = ['lora_A', 'lora_B', 'lora_embedding_A', 'lora_embedding_B']
        return any(keyword in param_name for keyword in lora_keywords)


class FedAttAggregator:
    """FedAttæ³¨æ„åŠ›èšåˆç®—æ³• - æ”¯æŒLoRA"""

    def __init__(self, epsilon=1.0, is_lora_mode=False):
        self.epsilon = epsilon
        self.is_lora_mode = is_lora_mode

    def aggregate(self, client_models: List[Dict], client_weights: List[float] = None):
        if self.is_lora_mode:
            # åˆ†ç±»æ‰€æœ‰å®¢æˆ·ç«¯å‚æ•°
            all_lora = []
            all_timellm = []

            for model in client_models:
                lora_params, timellm_params, _ = self._classify_parameters(model)
                all_lora.append(lora_params)
                all_timellm.append(timellm_params)

            # åˆ†åˆ«å¯¹LoRAå’ŒTimeLLMå‚æ•°åº”ç”¨æ³¨æ„åŠ›èšåˆ
            aggregated_lora = self._average_weights_att(all_lora, all_lora[0]) if all_lora and all_lora[0] else {}
            aggregated_timellm = self._average_weights_att(all_timellm, all_timellm[0]) if all_timellm and all_timellm[
                0] else {}

            # é‡æ„å®Œæ•´æ¨¡å‹
            return self._reconstruct_full_model(aggregated_lora, aggregated_timellm, client_models[0])
        else:
            # æ ‡å‡†æ¨¡å¼ï¼šæ‰€æœ‰å‚æ•°
            return self._average_weights_att(client_models, client_models[0])

    def _average_weights_att(self, w_clients, w_server):  # ç§»é™¤epsilonå‚æ•°
        """æ³¨æ„åŠ›åŠ æƒèšåˆ"""
        epsilon = self.epsilon  # ä½¿ç”¨å®ä¾‹å˜é‡

        w_next = copy.deepcopy(w_server)
        att = {}
        for k in w_server.keys():
            w_next[k] = torch.zeros_like(w_server[k])
            att[k] = torch.zeros(len(w_clients))

        for k in w_next.keys():
            for i in range(0, len(w_clients)):
                att[k][i] = torch.from_numpy(np.array(linalg.norm(w_server[k].cpu() - w_clients[i][k].cpu())))

        for k in w_next.keys():
            att[k] = torch.nn.functional.softmax(att[k], dim=0)

        for k in w_next.keys():
            att_weight = torch.zeros_like(w_server[k])
            for i in range(0, len(w_clients)):
                att_weight += torch.mul(w_server[k] - w_clients[i][k], att[k][i])

            w_next[k] = w_server[k] - torch.mul(att_weight, epsilon)

        return w_next

    def _reconstruct_full_model(self, lora_result, timellm_result, reference_model):
        """é‡æ„å®Œæ•´æ¨¡å‹ï¼šèšåˆåçš„å¯è®­ç»ƒå‚æ•° + å†»ç»“çš„LLMå‚æ•°"""
        full_model = copy.deepcopy(reference_model)

        # æ›´æ–°LoRAå‚æ•°
        for key, value in lora_result.items():
            full_model[key] = value

        # æ›´æ–°TimeLLMå‚æ•°
        for key, value in timellm_result.items():
            full_model[key] = value

        return full_model

    def _classify_parameters(self, model_params):
        """åˆ†ç±»æ¨¡å‹å‚æ•°"""
        lora_params = {}
        timellm_params = {}
        frozen_params = {}

        for key, value in model_params.items():
            if self._is_lora_param(key):
                lora_params[key] = value
            elif self._is_timellm_param(key):
                timellm_params[key] = value
            else:
                frozen_params[key] = value  # LLMåŸºç¡€å‚æ•°

        return lora_params, timellm_params, frozen_params

    def _is_timellm_param(self, param_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºTimeLLMå±‚å‚æ•°"""
        timellm_keywords = [
            'ts2language',  # æ—¶åºæ˜ å°„å±‚
            'output_projection',  # è¾“å‡ºæŠ•å½±å±‚
            'normalize_layers',  # å½’ä¸€åŒ–å±‚
            'patch_embedding'  # è¡¥ä¸åµŒå…¥å±‚
        ]
        return any(keyword in param_name for keyword in timellm_keywords)

    def _extract_lora_params(self, client_models):
        """æå–LoRAå‚æ•° - å¤ç”¨ç°æœ‰é€»è¾‘"""
        lora_models = []
        for model in client_models:
            lora_params = {}
            for key, value in model.items():
                if self._is_lora_param(key):  # å¤ç”¨ç°æœ‰å‡½æ•°
                    lora_params[key] = value
            lora_models.append(lora_params)
        return lora_models

    def _is_lora_param(self, param_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºLoRAå‚æ•° - å¤ç”¨ç°æœ‰é€»è¾‘"""
        lora_keywords = ['lora_A', 'lora_B', 'lora_embedding_A', 'lora_embedding_B']
        return any(keyword in param_name for keyword in lora_keywords)


class FedDAAggregator:
    """FedDAåŒæ³¨æ„åŠ›èšåˆç®—æ³• - å®Œæ•´ç‰ˆ"""

    def __init__(self, num_clusters=3, rho=0.1, gamma=0.01,
                 enable_augmentation=True, augment_ratio=0.01):
        self.num_clusters = num_clusters
        self.rho = rho
        self.gamma = gamma
        self.enable_augmentation = enable_augmentation
        self.augment_ratio = augment_ratio

        # åˆå§‹åŒ–ç»„ä»¶
        if self.enable_augmentation:
            from .data_augmentation import FedDADataAugmentation
            self.data_augmenter = FedDADataAugmentation(augment_ratio)

        from .geographic_clustering import FedDAGeographicClustering
        self.geo_clusterer = FedDAGeographicClustering(num_clusters)

        self.quasi_global_model = None
        self.clusters = None
        self.is_initialized = False

    def aggregate(self, client_models: List[Dict], client_info: List[Dict] = None,
                  federated_data: Dict = None, round_idx: int = 0):
        """
        å®Œæ•´çš„FedDAèšåˆè¿‡ç¨‹

        Args:
            client_models: å®¢æˆ·ç«¯æ¨¡å‹å‚æ•°
            client_info: å®¢æˆ·ç«¯ä¿¡æ¯
            federated_data: è”é‚¦æ•°æ®ï¼ˆåŒ…å«åæ ‡ç­‰ï¼‰
            round_idx: å½“å‰è½®æ¬¡
        """
        # ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶è¿›è¡Œåˆå§‹åŒ–
        if not self.is_initialized and federated_data is not None:
            self._initialize_fedda(federated_data, client_info)
            self.is_initialized = True

        # æ ¹æ®èšç±»ç»“æœç»„ç»‡å®¢æˆ·ç«¯æ¨¡å‹
        if self.clusters:
            clustered_models = self._organize_models_by_cluster(client_models, client_info)
        else:
            # å›é€€åˆ°ç®€å•èšç±»
            clustered_models = self._simple_clustering(client_models)

        # æ­¥éª¤1ï¼šç°‡å†…èšåˆ
        cluster_models = []
        for cluster_models_list in clustered_models.values():
            if cluster_models_list:
                cluster_model = self._dual_attention_aggregation(cluster_models_list)
                cluster_models.append(cluster_model)

        # æ­¥éª¤2ï¼šç°‡é—´èšåˆ
        if cluster_models:
            global_model = self._dual_attention_aggregation(cluster_models)
        else:
            global_model = copy.deepcopy(client_models[0]) if client_models else {}

        return global_model

    def _initialize_fedda(self, federated_data: Dict, client_info: List[Dict]):
        """åˆå§‹åŒ–FedDAç»„ä»¶"""
        print("ğŸ”§ åˆå§‹åŒ–FedDAç»„ä»¶...")

        augmented_data = {}

        # æ•°æ®å¢å¼º
        if self.enable_augmentation:
            print("  ğŸ“Š æ‰§è¡Œæ•°æ®å¢å¼º...")
            for client_id, client_data in federated_data['clients'].items():
                augmented_sample = self.data_augmenter.augment_client_data(
                    client_data, client_id
                )
                if augmented_sample is not None:
                    augmented_data[client_id] = augmented_sample

            print(f"  âœ… å®Œæˆ {len(augmented_data)} ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®å¢å¼º")

        # åœ°ç†èšç±»
        if augmented_data:
            print("  ğŸ—ºï¸  æ‰§è¡Œåœ°ç†ä½ç½®èšç±»...")
            self.clusters = self.geo_clusterer.iterative_clustering(
                federated_data, augmented_data
            )
            print(f"  âœ… èšç±»å®Œæˆ: {len(self.clusters)} ä¸ªç°‡")
            for cluster_id, client_list in self.clusters.items():
                print(f"    ç°‡ {cluster_id}: {len(client_list)} ä¸ªå®¢æˆ·ç«¯")

        print("ğŸ¯ FedDAåˆå§‹åŒ–å®Œæˆ!")

    def _organize_models_by_cluster(self, client_models, client_info):
        """æ ¹æ®èšç±»ç»“æœç»„ç»‡æ¨¡å‹"""
        clustered_models = {i: [] for i in range(self.num_clusters)}

        for i, (model, info) in enumerate(zip(client_models, client_info)):
            client_id = info['client_id']
            cluster_id = self.geo_clusterer.get_client_cluster(client_id)
            clustered_models[cluster_id].append(model)

        return clustered_models

    def _dual_attention_aggregation(self, models):
        """æ ¸å¿ƒï¼šåŒæ³¨æ„åŠ›èšåˆç®—æ³•"""
        if not models:
            return {}

        if len(models) == 1:
            return copy.deepcopy(models[0])

        # åˆå§‹åŒ–è¾“å‡ºæ¨¡å‹
        output_model = copy.deepcopy(models[0])

        # å¯¹æ¯ä¸ªå‚æ•°å±‚åº”ç”¨æ³¨æ„åŠ›æœºåˆ¶
        for param_name in output_model.keys():
            # è®¡ç®—æ³¨æ„åŠ›æƒé‡
            attention_weights = self._compute_attention_weights(
                models, param_name, output_model[param_name]
            )

            # åº”ç”¨æ³¨æ„åŠ›åŠ æƒæ›´æ–°
            output_model[param_name] = self._apply_attention_update(
                models, param_name, output_model[param_name], attention_weights
            )

        return output_model

    def _compute_attention_weights(self, models, param_name, output_param):
        """è®¡ç®—å±‚çº§æ³¨æ„åŠ›æƒé‡"""
        distances = []

        for model in models:
            if param_name in model:
                # è®¡ç®—FrobeniusèŒƒæ•°è·ç¦»
                dist = torch.norm(model[param_name] - output_param, p='fro').item()
                distances.append(dist)
            else:
                distances.append(float('inf'))

        # åº”ç”¨softmaxè·å¾—æ³¨æ„åŠ›æƒé‡
        distances = torch.tensor(distances)
        attention_weights = torch.softmax(-distances, dim=0)  # è·ç¦»è¶Šå°æƒé‡è¶Šå¤§

        return attention_weights

    def _apply_attention_update(self, models, param_name, output_param, attention_weights):
        """åº”ç”¨æ³¨æ„åŠ›æƒé‡æ›´æ–°å‚æ•°"""
        # æ¢¯åº¦è®¡ç®—
        gradient = torch.zeros_like(output_param)

        for i, model in enumerate(models):
            if param_name in model:
                gradient += attention_weights[i] * (output_param - model[param_name])

        # æ·»åŠ å‡†å…¨å±€æ¨¡å‹çš„æ­£åˆ™åŒ–é¡¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.quasi_global_model and param_name in self.quasi_global_model:
            beta = 1.0  # å‡†å…¨å±€æ¨¡å‹æƒé‡
            gradient += self.rho * beta * (output_param - self.quasi_global_model[param_name])

        # æ¢¯åº¦ä¸‹é™æ›´æ–°
        updated_param = output_param - self.gamma * gradient

        return updated_param

    # éœ€è¦æ·»åŠ è¿™ä¸ªæ–¹æ³•
    def _simple_clustering(self, client_models):
        """ç®€å•èšç±»å›é€€æ–¹æ¡ˆ"""
        clusters = {i: [] for i in range(self.num_clusters)}
        for i, model in enumerate(client_models):
            cluster_id = i % self.num_clusters
            clusters[cluster_id].append(model)
        return clusters

def get_aggregator(aggregation_method: str, **kwargs):
    """
    è·å–èšåˆå™¨

    Args:
        aggregation_method: èšåˆæ–¹æ³•åç§°
        **kwargs: é¢å¤–å‚æ•°ï¼Œç”¨äºLLMèšåˆå™¨

    Returns:
        aggregator: èšåˆå™¨å®ä¾‹
    """
    if aggregation_method.lower() == 'fedavg':
        return FedAvgAggregator()
    elif aggregation_method.lower() == 'weighted':
        return WeightedFedAvgAggregator()
    elif aggregation_method.lower() == 'lora_fedavg':
        return LoRAFedAvgAggregator()
    elif aggregation_method.lower() == 'lora_fedprox':  # æ–°å¢: LoRAç‰ˆæœ¬çš„FedProx
        return LoRAFedAvgAggregator()  # FedProxèšåˆé˜¶æ®µä¸LoRA FedAvgç›¸åŒ
    elif aggregation_method.lower() == 'fedprox':  # ä¿ç•™éLoRAç‰ˆæœ¬
        return FedAvgAggregator()
    elif aggregation_method.lower() == 'fedatt':
        epsilon = kwargs.get('fedatt_epsilon', 1.0)
        is_lora_mode = kwargs.get('is_lora_mode', False)  # ä¼ å…¥LoRAæ¨¡å¼æ ‡å¿—
        return FedAttAggregator(epsilon, is_lora_mode)
    elif aggregation_method.lower() == 'fedda':
        num_clusters = kwargs.get('fedda_clusters', 2)
        rho = kwargs.get('fedda_rho', 0.1)
        gamma = kwargs.get('fedda_gamma', 0.01)
        return FedDAAggregator(num_clusters, rho, gamma)
    elif aggregation_method.lower() == 'enhanced_multi_dim_llm':
        from .enhanced_multi_dimensional_llm_aggregator import EnhancedMultiDimensionalLLMAggregator

        # æ·»åŠ æ–°çš„å‚æ•°ä¼ é€’
        aggregator_kwargs = kwargs.copy()
        aggregator_kwargs.update({
            'alpha_max': kwargs.get('alpha_max', 0.9),
            'alpha_min': kwargs.get('alpha_min', 0.2),
            'decay_type': kwargs.get('decay_type', 'sigmoid'),
            'base_constraint': kwargs.get('base_constraint', 0.25),
        })

        return EnhancedMultiDimensionalLLMAggregator(**aggregator_kwargs)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„èšåˆæ–¹æ³•: {aggregation_method}")